name: main
on:
  workflow_dispatch:

permissions:
  contents: read
  issues: write

jobs:

  set-aws-credentials:
    runs-on: ubuntu-latest
    env:
      SA_JSON: ${{ secrets.SA_JSON }}
      SA_FILE: "sa.json"
      SCHEMA_DIR: "./.github/schemas"
      ARN_ADMINISTRATOR: arn:aws:iam::aws:policy/AdministratorAccess
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Save SA_JSON as file
        run: printf '%s' "$SA_JSON" > $SA_FILE
      - name: Validate SA_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.SA_FILE }}"
          files:  ${{ env.SA_FILE }}
          comment: "true"
      - name: Check user is valid (STS)
        run: |
          if aws sts get-caller-identity >/dev/null 2>&1; then
            echo "OK: credentials are valid"
          else
            echo "ERROR: invalid AWS credentials (sts get-caller-identity failed)"
            exit 1
          fi
      - name: Get User policy ARN
        id: arn-user
        run: |
          ARN="$(aws sts get-caller-identity --query Arn --output text)"
          echo "arn_user=$ARN" >> "$GITHUB_OUTPUT"
      - name: Check attached managed policy is AdministratorAccess
        env:
          ARN_USER: ${{ steps.arn-user.outputs.arn_user }}
        run: |
          COUNT="$(aws iam list-attached-user-policies \
            --user-name "${ARN_USER##*/}" \
            --query "AttachedPolicies[?PolicyArn=='${ARN_ADMINISTRATOR}'] | length(@)" \
            --output text)"
          if [[ "$COUNT" = "1" ]]; then
            echo "OK: user has AdministratorAccess attached"
          else
            echo "ERROR: user does NOT have AdministratorAccess attached"
            exit 1
          fi

  generate-vars:
    runs-on: ubuntu-latest
    env:
      VARS_JSON: ${{ vars.VARS_JSON }}
      VARS_FILE: "vars.json"
      SCHEMA_DIR: "./.github/schemas"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Save VARS_JSON as file
        run: printf '%s' "$VARS_JSON" > $VARS_FILE
      - name: Validate VARS_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.VARS_FILE }}"
          files:  ${{ env.VARS_FILE }}
          comment: "true"
      - name: Generate tf_vars.json
        run: |
          echo "Storing keys into tf_vars.json:"
          echo "$VARS_JSON" | jq -r 'keys[]' | sed "s/^/ - /"
          printf '%s\n' "$VARS_JSON" > tf_vars.json
      - name: Upload tf_vars.json
        uses: actions/upload-artifact@v4
        with:
          name: tf_vars
          path: tf_vars.json

  generate-secrets:
    runs-on: ubuntu-latest
    env:
      SECRETS_JSON: ${{ secrets.SECRETS_JSON }}
      SECRETS_FILE: "secrets.json"
      SCHEMA_DIR: "./.github/schemas"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Save SECRETS_JSON as file
        run: printf '%s' "$SECRETS_JSON" > $SECRETS_FILE
      - name: Validate SECRETS_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.SECRETS_FILE }}"
          files:  ${{ env.SECRETS_FILE }}
          comment: "true"
      - name: Generate tf_secrets.json
        run: |
          echo "Storing keys into tf_secrets.json:"
          echo "$SECRETS_JSON" | jq -r 'keys[]' | sed "s/^/ - /"
          printf '%s\n' "$SECRETS_JSON" > tf_secrets.json
      - name: Upload tf_secrets.json
        uses: actions/upload-artifact@v4
        with:
          name: tf_secrets
          path: tf_secrets.json

  prepare-artifacts:
    runs-on: ubuntu-latest
    env:
      BUILD_DIR: build
      ARTIFACTS_DIR: artifacts
      LAMBDA_DIR: lambda
      PYTHON_DIR: python
      NODEJS_DIR: nodejs
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
      - name: Cache python lambda build
        id: cache-artifacts-python
        uses: actions/cache@v4
        with:
          path: ${{ env.BUILD_DIR }}/${{ env.LAMBDA_DIR }}/$PYTHON_DIR/**/packages
          key: ${{ runner.os }}-lambda-python-${{ hashFiles('build/lambda/**') }}
          restore-keys: |
            ${{ runner.os }}-lambda-python-artifacts-
      - name: Cache nodejs lambda build
        id: cache-artifacts-nodejs
        uses: actions/cache@v4
        with:
          path: ${{ env.BUILD_DIR }}/${{ env.LAMBDA_DIR }}/$NODEJS_DIR/**/node_modules
          key: ${{ runner.os }}-lambda-node-${{ hashFiles('build/lambda/**') }}
          restore-keys: |
            ${{ runner.os }}-lambda-node-artifacts-
      - name: Build lambda python
        if: steps.cache-artifacts-python.outputs.cache-hit != 'true'
        run: |
          for d in "$BUILD_DIR/$LAMBDA_DIR/$PYTHON_DIR"/*; do
            if [[ -f "$d/requirements.txt" ]]; then
              echo "Building python lambda $(basename "$d")"
              mkdir -p "$d/packages"
              python -m pip install -r "$d/requirements.txt" -t "$d/packages"
              echo "Built python lambda $(basename "$d")"
            else
              echo "Skipped python lambda $(basename "$d") (no requirements.txt)"
            fi
          done
      - name: Build lambda nodejs
        if: steps.cache-artifacts-nodejs.outputs.cache-hit != 'true'
        run: |
          for d in "$BUILD_DIR/$LAMBDA_DIR/$NODEJS_DIR"/*; do
            if [[ -f "$d/package.json" ]]; then
              echo "Building node lambda $(basename "$d")"
              (cd "$d" && npm ci --omit=dev)
              echo "Built node lambda $(basename "$d")"
            else
              echo "Skipped node lambda $(basename "$d") (no package.json)"
            fi
          done
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: artifacts
          path: build

  generate-modules:
    runs-on: ubuntu-latest
    env:
      MODULES_JSON: ${{ vars.MODULES_JSON }}
      MODULES_FILE: modules.json
      SCHEMA_DIR: ./.github/schemas
      MODULES_DIR: ./modules
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Save MODULES_JSON as file
        run: printf '%s' "$MODULES_JSON" > "$MODULES_FILE"
      - name: Validate modules.json
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.MODULES_FILE }}"
          files: ${{ env.MODULES_FILE }}
          comment: "true"
      # If you need private repos, uncomment the SSH setup and use git@github.com:... below.
      # - name: Setup SSH
      #   uses: webfactory/ssh-agent@v0.9.0
      #   with:
      #     ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}
      - name: Download all module repos
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "$MODULES_DIR"
          echo "$MODULES_JSON" | jq -r '.[] | "\(.owner) \(.repo)"' | while read -r owner repo; do
            dest="$MODULES_DIR/$repo"
            mkdir -p "$(dirname "$dest")"
            echo "Cloning ${owner}/${repo} -> ${dest}"
            # Public repos:
            git clone --depth 1 "https://github.com/${owner}/${repo}.git" "$dest"
            # Private repos via SSH (requires SSH setup step above):
            # git clone --depth 1 "git@github.com:${owner}/${repo}.git" "$dest"
            rm -rf "$dest/.git"
          done
      - name: Upload modules artifact
        uses: actions/upload-artifact@v4
        with:
          name: modules
          path: ${{ env.MODULES_DIR }}
          if-no-files-found: error

  generate-tfbackend:
    runs-on: ubuntu-latest
    needs:
      - set-aws-credentials
      - generate-secrets
      - generate-vars
    env:
      BUCKET_NAME: ${{ fromJson(vars.VARS_JSON).project_name }}-bucket-tfstate
      AWS_REGION: ${{ fromJson(secrets.SA_JSON).aws_region }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Creates / Checks state bucket
        run: |
          set -euo pipefail
          if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
            echo "Bucket already exists: $BUCKET_NAME"
          else
            echo "Bucket does not exist. Creating: $BUCKET_NAME"
            aws s3api create-bucket --bucket "$BUCKET_NAME" \
              --region "$AWS_REGION" \
              --create-bucket-configuration LocationConstraint="$AWS_REGION"
            echo "Applying public access block to $BUCKET_NAME"
            aws s3api put-public-access-block --bucket "$BUCKET_NAME" --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
            echo "Enabling versioning for $BUCKET_NAME"
            aws s3api put-bucket-versioning --bucket "$BUCKET_NAME" --versioning-configuration Status=Enabled
            echo "Enabling default encryption (SSE-S3) for $BUCKET_NAME"
            aws s3api put-bucket-encryption --bucket "$BUCKET_NAME" --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
          fi
      - name: Create TF Backend (backend.tf)
        run: |
          tee backend.tf > /dev/null <<EOF
          terraform {
            backend "s3" {
              bucket       = "$BUCKET_NAME"
              key          = "terraform.tfstate"
              use_lockfile = true
              region       = "$AWS_REGION"
              encrypt      = true
            }
          }
          EOF
          echo "backend.tf created"
      - name: Upload backend.tf
        uses: actions/upload-artifact@v4
        with:
          name: tfbackend
          path: backend.tf

  tf-plan:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs:
      - set-aws-credentials
      - generate-tfbackend
      - generate-vars
      - generate-secrets
      - generate-modules
    env:
      TF_PLUGIN_CACHE_DIR: ${{ github.workspace }}/.terraform.d/plugin-cache
      MODULES_DIR: ./modules
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Terraform CLI
        uses: hashicorp/setup-terraform@v3
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Download tfbackend
        uses: actions/download-artifact@v4
        with:
          name: tfbackend
          path: ""
      - name: Download tf_vars
        uses: actions/download-artifact@v4
        with:
          name: tf_vars
          path: ""
      - name: Download tf_secrets
        uses: actions/download-artifact@v4
        with:
          name: tf_secrets
          path: ""
      - name: Download modules
        uses: actions/download-artifact@v4
        with:
          name: modules
          path: ${{ env.MODULES_DIR }}
          if-no-files-found: error
      - name: Create plugin cache dir
        run: mkdir -p "${TF_PLUGIN_CACHE_DIR}"
      - name: Cache Terraform providers
        id: tfinit-providers
        uses: actions/cache@v4
        with:
          path: ${{ env.TF_PLUGIN_CACHE_DIR }}
          key: ${{ runner.os }}-tfinit-providers-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-tfproviders-
      - name: Terraform init
        run: terraform init -input=false -lockfile=readonly
      - name: Terraform plan
        run: terraform plan -input=false -no-color -out=tfplan -var-file="tf_secrets.json" -var-file="tf_vars.json"
      - name: Generate visual plan
        run: terraform show -no-color tfplan > tfplan_visual
      - name: Upload tfplan_visual
        uses: actions/upload-artifact@v4
        with:
          name: tfplan_visual
          path: tfplan_visual
      - name: Upload tfplan
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: tfplan

  approbal:
    runs-on: ubuntu-latest
    needs: tf-plan
    steps:
      - name: Download tfplan_visual
        uses: actions/download-artifact@v4
        with:
          name: tfplan_visual
          path: .
      - name: Await Manual Approval
        timeout-minutes: 5
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ secrets.GITHUB_TOKEN }}
          minimum-approvals: 1
          approvers: ${{ github.actor }}
          issue-title: "Manual Approval Required for Terraform Apply"
          issue-body-file-path: tfplan_visual

  tf-apply:
    runs-on: ubuntu-latest
    needs:
      - approbal
      - prepare-artifacts
      - generate-modules
    env:
      TF_PLUGIN_CACHE_DIR: ${{ github.workspace }}/.terraform.d/plugin-cache
      ARTIFACTS_DIR: "./artifacts"
      SCRIPTS_DIR: "./scripts"
      MODULES_DIR:  "./modules"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Terraform CLI
        uses: hashicorp/setup-terraform@v3
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Install Ansible
        run: sudo apt-get update && sudo apt-get install -y ansible
      - name: Create tf providers dir
        run: mkdir -p "${TF_PLUGIN_CACHE_DIR}"
      - name: Set execute permissions for scripts
        run: |
          if [ -d $SCRIPTS_DIR ]; then
            chmod +x $SCRIPTS_DIR/*.sh || true
            ls -l $SCRIPTS_DIR
          else
            echo "Directory $SCRIPTS_DIR does not exist"
            exit 1
          fi
      - name: Download tfplan
        uses: actions/download-artifact@v4
        with:
          name: tfplan
          path: ""
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: artifacts
          path: ${{ env.ARTIFACTS_DIR }}       
      - name: Download modules
        uses: actions/download-artifact@v4
        with:
          name: modules
          path: ${{ env.MODULES_DIR }}
      - name: Cache Terraform providers (plugin cache)
        id: tfinit-providers
        uses: actions/cache@v4
        with:
          path: ${{ env.TF_PLUGIN_CACHE_DIR }}
          key: ${{ runner.os }}-tfinit-providers-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-tfinit-providers-
      - name: Terraform init
        run: terraform init -input=false -lockfile=readonly
      - name: Terraform apply
        run: terraform apply -auto-approve tfplan