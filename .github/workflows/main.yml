name: main
on:
  workflow_dispatch:

permissions:
  contents: read
  issues: write

jobs:

  check-repo-structure:
    runs-on: ubuntu-latest
    env:
      REQUIRED_FILES: bootstrap.sh data.tf locals.tf main.tf providers.tf secrets.tf variables.tf README.md .terraform.lock.hcl
      REQUIRED_FOLDERS: packages scripts modules
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Files check
        shell: bash
        run: |
          for f in $REQUIRED_FILES; do
            test -f "$f" || { echo "::error title=Missing file::$f"; exit 1; }
          done
      - name: Folders check
        shell: bash
        run: |
          for d in $REQUIRED_FOLDERS; do
            test -d "$d" || { echo "::error title=Missing directory::$d does not exist"; exit 1; }
          done

  check-schemas:
    runs-on: ubuntu-latest
    env:
      SA_JSON: ${{ secrets.SA_JSON }}
      SA_FILE: "sa.json"
      VARS_FILE: "vars.json"
      SECRETS_FILE: "secrets.json"
      MODULES_FILE: "modules.json"
      SCHEMA_DIR: "./.github/schemas"
      ARN_ADMINISTRATOR: arn:aws:iam::aws:policy/AdministratorAccess
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Save SA_JSON as file
        run: printf '%s' "$SA_JSON" > "$SA_FILE"
      - name: Save VARS_JSON as file
        run: printf '%s' "$VARS_JSON" > "$VARS_FILE"
      - name: Save SECRETS_JSON as file
        run: printf '%s' "$SECRETS_JSON" > "$SECRETS_FILE"
      - name: Save MODULES_JSON as file
        run: printf '%s' "$MODULES_JSON" > "$MODULES_FILE"
      - name: Validate SA_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.SA_FILE }}"
          files: ${{ env.SA_FILE }}
          comment: "true"
      - name: Validate VARS_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.VARS_FILE }}"
          files: ${{ env.VARS_FILE }}
          comment: "true"
      - name: Validate SECRETS_JSON
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.SECRETS_FILE }}"
          files: ${{ env.SECRETS_FILE }}
          comment: "true"
      - name: Validate modules.json
        uses: GrantBirki/json-yaml-validate@v4.0.0
        with:
          json_schema: "${{ env.SCHEMA_DIR }}/${{ env.MODULES_FILE }}"
          files: ${{ env.MODULES_FILE }}
          comment: "true"

  check-aws-credentials:
    runs-on: ubuntu-latest
    env:
      SA_JSON: ${{ secrets.SA_JSON }}
      ARN_ADMINISTRATOR: arn:aws:iam::aws:policy/AdministratorAccess
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Check user is valid (STS)
        run: |
          if aws sts get-caller-identity >/dev/null 2>&1; then
            echo "OK: credentials are valid"
          else
            echo "ERROR: invalid AWS credentials (sts get-caller-identity failed)"
            exit 1
          fi
      - name: Get User policy ARN
        id: arn-user
        run: |
          ARN="$(aws sts get-caller-identity --query Arn --output text)"
          echo "arn_user=$ARN" >> "$GITHUB_OUTPUT"
      - name: Check attached managed policy is AdministratorAccess
        env:
          ARN_USER: ${{ steps.arn-user.outputs.arn_user }}
        run: |
          COUNT="$(aws iam list-attached-user-policies \
            --user-name "${ARN_USER##*/}" \
            --query "AttachedPolicies[?PolicyArn=='${ARN_ADMINISTRATOR}'] | length(@)" \
            --output text)"
          if [[ "$COUNT" = "1" ]]; then
            echo "OK: user has AdministratorAccess attached"
          else
            echo "ERROR: user does NOT have AdministratorAccess attached"
            exit 1
          fi

  generate-tf-vars:
    runs-on: ubuntu-latest
    env:
      VARS_JSON: ${{ vars.VARS_JSON }}
    steps:
      - name: Generate tf_vars.json
        run: |
          echo "Storing keys into tf_vars.json:"
          echo "$VARS_JSON" | jq -r 'keys[]' | sed "s/^/ - /"
          printf '%s\n' "$VARS_JSON" > tf_vars.json
      - name: Upload tf_vars.json
        uses: actions/upload-artifact@v4
        with:
          name: tf_vars.json
          path: tf_vars.json

  generate-tf-secrets:
    runs-on: ubuntu-latest
    env:
      SECRETS_JSON: ${{ secrets.SECRETS_JSON }}
    steps:
      - name: Generate tf_secrets.json
        run: |
          echo "Storing keys into tf_secrets.json:"
          echo "$SECRETS_JSON" | jq -r 'keys[]' | sed "s/^/ - /"
          printf '%s\n' "$SECRETS_JSON" > tf_secrets.json
      - name: Upload tf_secrets.json
        uses: actions/upload-artifact@v4
        with:
          name: tf_secrets.json
          path: tf_secrets.json

  generate-artifacts:
    runs-on: ubuntu-latest
    env:
      PACKAGES_DIR: "packages"
      PACKAGES_LAMBDA_DIR: "packages/lambda"
      PACKAGES_ANSIBLE_DIR: "packages/ansible"
      ARTIFACTS_LAMBDA_DIR: "artifacts/lambda"
      ARTIFACTS_ANSIBLE_DIR: "artifacts/ansible"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
      - name: Create artifacts folders
        run: |
          mkdir -p $ARTIFACTS_LAMBDA_DIR
          mkdir -p $ARTIFACTS_ANSIBLE_DIR
      - name: Build lambda python
        run: |
          for d in "${PACKAGES_LAMBDA_DIR%/}/"*/; do
            if [[ -f "${d}requirements.txt" ]]; then
              echo "Building python lambda $(basename "${d%/}")"
              mkdir -p "${d}packages"
              python -m pip install -r "${d}requirements.txt" -t "${d}packages"
              echo "Built python lambda $(basename "${d%/}")"
            else
              echo "Skipped python lambda $(basename "${d%/}") (no requirements.txt)"
            fi
          done
      - name: Build lambda nodejs
        run: |
          for d in "${PACKAGES_LAMBDA_DIR%/}/"*/; do
            if [[ -f "${d}package.json" ]]; then
              echo "Building node lambda $(basename "${d%/}")"
              (cd "$d" && npm ci --omit=dev)
              echo "Built node lambda $(basename "${d%/}")"
            else
              echo "Skipped node lambda $(basename "${d%/}") (no package.json)"
            fi
          done
      - name: Pack lambda python
        run: |
          for d in "${PACKAGES_LAMBDA_DIR%/}/"*/; do
            if [[ -f "${d}requirements.txt" ]] || [[ -d "${d}packages" ]]; then
              name="$(basename "${d%/}")"
              zip_path="${PACKAGES_LAMBDA_DIR%/}/${name}.zip"
              echo "Packing python lambda: ${d} -> ${zip_path}"
              (cd "$d" && zip -r -q "$GITHUB_WORKSPACE/$zip_path" . \
                -x ".venv/*" ".venv/**" "__pycache__/*" "__pycache__/**" \
                  ".pytest_cache/*" ".pytest_cache/**" ".mypy_cache/*" ".mypy_cache/**" \
                  ".DS_Store" "*.pyc")
              echo "Packed: ${zip_path}"
            fi
          done
      - name: Pack lambda nodejs
        run: |
          for d in "${PACKAGES_LAMBDA_DIR%/}/"*/; do
            if [[ -f "${d}package.json" ]] || [[ -d "${d}node_modules" ]]; then
              name="$(basename "${d%/}")"
              zip_path="${PACKAGES_LAMBDA_DIR%/}/${name}.zip"
              echo "Packing nodejs lambda: ${d} -> ${zip_path}"
              (cd "$d" && zip -r -q "$GITHUB_WORKSPACE/$zip_path" . \
                -x ".DS_Store")
              echo "Packed: ${zip_path}"
            fi
          done
      - name: Pack ansible
        run: |
          for d in "${PACKAGES_ANSIBLE_DIR%/}/"*/; do
            name="$(basename "${d%/}")"
            zip_path="${PACKAGES_ANSIBLE_DIR%/}/${name}.zip"
            echo "Packing Ansible Playbook of ${d} -> ${zip_path}"
            (cd "$d" && zip -r -q "$GITHUB_WORKSPACE/$zip_path" .)
            echo "Packed: ${zip_path}"
          done
      - name: Upload src
        uses: actions/upload-artifact@v4
        with:
          name: src
          path: src

  generate-modules:
    runs-on: ubuntu-latest
    env:
      MODULES_JSON: ${{ vars.MODULES_JSON }}
      MODULES_DIR: ./modules
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Download all module repos
        shell: bash
        run: |
          set -euo pipefail
          echo "$MODULES_JSON" | jq -r '.[] | "\(.owner) \(.repo)"' | while read -r owner repo; do
            dest="$MODULES_DIR/$repo"
            mkdir -p "$(dirname "$dest")"
            echo "Cloning ${owner}/${repo} -> ${dest}"
            git clone --depth 1 "https://github.com/${owner}/${repo}.git" "$dest"
            rm -rf "$dest/.git"
          done
      - name: Upload modules artifact
        uses: actions/upload-artifact@v4
        with:
          name: modules
          path: ${{ env.MODULES_DIR }}
          if-no-files-found: error

  generate-tf-backend:
    runs-on: ubuntu-latest
    needs:
      - check-aws-credentials
      - generate-tf-vars
    env:
      BUCKET_NAME: ${{ fromJson(vars.VARS_JSON).project_name }}-bucket-tfstate
      AWS_REGION: ${{ fromJson(secrets.SA_JSON).aws_region }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Creates / Checks state bucket
        run: |
          set -euo pipefail
          if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
            echo "Bucket already exists: $BUCKET_NAME"
          else
            echo "Bucket does not exist. Creating: $BUCKET_NAME"
            aws s3api create-bucket --bucket "$BUCKET_NAME" \
              --region "$AWS_REGION" \
              --create-bucket-configuration LocationConstraint="$AWS_REGION"
            echo "Applying public access block to $BUCKET_NAME"
            aws s3api put-public-access-block --bucket "$BUCKET_NAME" --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
            echo "Enabling versioning for $BUCKET_NAME"
            aws s3api put-bucket-versioning --bucket "$BUCKET_NAME" --versioning-configuration Status=Enabled
            echo "Enabling default encryption (SSE-S3) for $BUCKET_NAME"
            aws s3api put-bucket-encryption --bucket "$BUCKET_NAME" --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
          fi
      - name: Create tf_backend.tf
        run: |
          tee tf_backend.tf > /dev/null <<EOF
          terraform {
            backend "s3" {
              bucket       = "$BUCKET_NAME"
              key          = "terraform.tfstate"
              use_lockfile = true
              region       = "$AWS_REGION"
              encrypt      = true
            }
          }
          EOF
          echo "tf_backend.tf created"
      - name: Upload tf_backend.tf
        uses: actions/upload-artifact@v4
        with:
          name: tf_backend.tf
          path: tf_backend.tf

  tf-plan:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs:
      - check-aws-credentials
      - generate-tf-vars
      - generate-tf-secrets
      - generate-tf-backend
      - generate-modules
      - generate-artifacts
    env:
      TF_PLUGIN_CACHE_DIR: ${{ github.workspace }}/.terraform.d/plugin-cache
      MODULES_DIR: ./modules
      PACKAGES_DIR: ./src
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Terraform CLI
        uses: hashicorp/setup-terraform@v3
      - name: Create plugin cache dir
        run: mkdir -p "${TF_PLUGIN_CACHE_DIR}"
      - name: Remove src content
        run: rm -rf "${PACKAGES_DIR}/*"
      - name: Create src dir
        run: mkdir -p "${PACKAGES_DIR}"
      - name: Terraform version
        run: terraform version
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Download tf_backend.tf
        uses: actions/download-artifact@v4
        with:
          name: tf_backend.tf
          path: ""
      - name: Download tf_vars
        uses: actions/download-artifact@v4
        with:
          name: tf_vars.json
          path: ""
      - name: Download tf_secrets
        uses: actions/download-artifact@v4
        with:
          name: tf_secrets.json
          path: ""
      - name: Download modules
        uses: actions/download-artifact@v4
        with:
          name: modules
          path: ""
      - name: Download src
        uses: actions/download-artifact@v4
        with:
          name: src
          path: ""
      - name: test1
        run: ls
      - name: test2
        run: |
          cd  src ; ls ; cd ansible/stack ; ls
      - name: Cache Terraform providers
        id: tfinit-providers
        uses: actions/cache@v4
        with:
          path: ${{ env.TF_PLUGIN_CACHE_DIR }}
          key: ${{ runner.os }}-tfinit-providers-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-tfproviders-
      - name: Terraform init
        run: terraform init -input=false -lockfile=readonly
      - name: Terraform plan
        run: terraform plan -input=false -no-color -out=tf_plan.out -var-file="tf_secrets.json" -var-file="tf_vars.json"
      - name: Generate visual plan
        run: terraform show -no-color tf_plan.out > tfplan_visual
      - name: Upload tfplan_visual
        uses: actions/upload-artifact@v4
        with:
          name: tfplan_visual
          path: tfplan_visual
      - name: Upload tf_plan.out
        uses: actions/upload-artifact@v4
        with:
          name: tf_plan.out
          path: tf_plan.out

  approbal:
    runs-on: ubuntu-latest
    needs: tf-plan
    steps:
      - name: Download tfplan_visual
        uses: actions/download-artifact@v4
        with:
          name: tfplan_visual
          path: .
      - name: Await Manual Approval
        timeout-minutes: 5
        uses: trstringer/manual-approval@v1
        with:
          secret: ${{ secrets.GITHUB_TOKEN }}
          minimum-approvals: 1
          approvers: ${{ github.actor }}
          issue-title: "Manual Approval Required for Terraform Apply"
          issue-body-file-path: tfplan_visual

  tf-apply:
    runs-on: ubuntu-latest
    needs:
      - approbal
      - generate-artifacts
    env:
      TF_PLUGIN_CACHE_DIR: ${{ github.workspace }}/.terraform.d/plugin-cache
      PACKAGES_DIR: "./src"
      SCRIPTS_DIR: "./scripts"
      MODULES_DIR: "./modules"
    steps:
      - name: Checkout repo
        uses: actions/checkout@v5
      - name: Setup Terraform CLI
        uses: hashicorp/setup-terraform@v3
      - name: Create tf providers dir
        run: mkdir -p "${TF_PLUGIN_CACHE_DIR}"
      - name: Create modules dir
        run: mkdir -p "${MODULES_DIR}"
      - name: Remove src content
        run: rm -rf "${PACKAGES_DIR}/*"
      - name: Create src dir
        run: mkdir -p "${PACKAGES_DIR}"
      - name: Set execute permissions for scripts
        run: |
          if [ -d $SCRIPTS_DIR ]; then
            chmod +x $SCRIPTS_DIR/*.sh || true
            ls -l $SCRIPTS_DIR
          else
            echo "Directory $SCRIPTS_DIR does not exist"
            exit 1
          fi
      - name: Terraform version
        run: terraform version
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ fromJson(secrets.SA_JSON).aws_access_key_id }}
          aws-secret-access-key: ${{ fromJson(secrets.SA_JSON).aws_secret_access_key }}
          aws-region: ${{ fromJson(secrets.SA_JSON).aws_region }}
      - name: Install Ansible
        run: sudo apt-get update && sudo apt-get install -y ansible
      - name: Download tf_backend.tf
        uses: actions/download-artifact@v4
        with:
          name: tf_backend.tf
          path: ""
      - name: Download tf_plan.out
        uses: actions/download-artifact@v4
        with:
          name: tf_plan.out
          path: ""
      - name: Download src
        uses: actions/download-artifact@v4
        with:
          name: src
          path: ""
      - name: Download modules
        uses: actions/download-artifact@v4
        with:
          name: modules
          path: ""
      - name: Cache Terraform providers (plugin cache)
        id: tfinit-providers
        uses: actions/cache@v4
        with:
          path: ${{ env.TF_PLUGIN_CACHE_DIR }}
          key: ${{ runner.os }}-tfinit-providers-${{ hashFiles('**/.terraform.lock.hcl') }}
          restore-keys: |
            ${{ runner.os }}-tfinit-providers-
      - name: Terraform init
        run: terraform init -input=false -lockfile=readonly
      - name: Terraform apply
        run: terraform apply -auto-approve tf_plan.out
